{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "def2c59a-742b-48f0-97d9-b21a7ffb2be7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting openai==1.13.3\n  Using cached openai-1.13.3-py3-none-any.whl (227 kB)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from openai==1.13.3) (1.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.13.3) (1.7.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.10/site-packages (from openai==1.13.3) (3.5.0)\nCollecting typing-extensions<5,>=4.7\n  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.10/site-packages (from openai==1.13.3) (1.10.6)\nRequirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.10/site-packages (from openai==1.13.3) (4.64.1)\nCollecting httpx<1,>=0.23.0\n  Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.4)\nCollecting httpcore==1.*\n  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2022.12.7)\nCollecting h11<0.15,>=0.13\n  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\nInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e97e821-aa9d-4b9f-8f41-3fd2b8521db2\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: openai\n    Found existing installation: openai 0.28.1\n    Not uninstalling openai at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e97e821-aa9d-4b9f-8f41-3fd2b8521db2\n    Can't uninstall 'openai'. No files were found to uninstall.\nSuccessfully installed h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 openai-1.13.3 typing-extensions-4.12.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "162af10a-1319-47d2-ae77-bd0677dcbb0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a934a5fd-8692-4d62-b9c6-074cc2c721cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai import AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6100715d-d298-43ff-9cc1-2045eab4f8a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "  try:\n",
    "        # Get configuration settings\n",
    "        # Configuration settings\n",
    "        azure_oai_endpoint = \"\"\n",
    "        azure_oai_key = \"\"\n",
    "        azure_oai_deployment =\"\"\n",
    "\n",
    "        # Configure the Azure OpenAI client\n",
    "        client = AsyncAzureOpenAI(\n",
    "            azure_endpoint = azure_oai_endpoint,\n",
    "            api_key=azure_oai_key,\n",
    "            api_version=\"2024-02-15-preview\"\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            prompt_input = input('Enter the code that you want to be generated (Press Q to quit):')\n",
    "\n",
    "            if prompt_input.lower() == 'q':\n",
    "                print('Exiting program...')\n",
    "                break\n",
    "            await call_openai_model(prompt_input, model=azure_oai_deployment, client=client)\n",
    "\n",
    "  except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "async def call_openai_model(prompt, model, client):\n",
    "    # Provide a basic user message, and use the prompt content as the user message\n",
    "    system_message = \"You are a Python 3.x expert that helps programmers write code. Please generate only the Python 3.x code with appropriate comments for the given user input. The code should be concise and logically correct. Please, strictly do not give any explanations on the code. Generate only python code with proper comments & docsrings, if necessary.\"\n",
    "    user_message = prompt\n",
    "\n",
    "    # Format and send the request to the model\n",
    "    messages =[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "\n",
    "    # Call the Azure OpenAI model\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    # Print the response to the console\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94873023-38ad-4d74-b623-e25f4d127655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the code that you want to be generated (Press Q to quit): Write a function to generate first n fibonacci terms"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def generate_fibonacci(n):\n    \"\"\"\n    Function to generate the first n Fibonacci terms.\n    \n    Parameters:\n    n (int): Number of terms\n    \n    Returns:\n    List[int]: List of the first n Fibonacci terms\n    \"\"\"\n    fibonacci = [0, 1]  # Initialize the Fibonacci sequence with the first two terms\n    \n    for i in range(2, n):\n        fibonacci.append(fibonacci[i-1] + fibonacci[i-2])  # Generate the next term by summing the previous two terms\n    \n    return fibonacci[:n]  # Return only the first n terms of the sequence\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the code that you want to be generated (Press Q to quit): How do i calculate MA(3) of item-date-sales data in pyspark?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Import necessary modules\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import lag, col\n\n# Create a SparkSession\nspark = SparkSession.builder.getOrCreate()\n\n# Create a DataFrame with item-date-sales data\ndata = [(1, '2020-01-01', 10),\n        (1, '2020-01-02', 15),\n        (1, '2020-01-03', 20),\n        (1, '2020-01-04', 25),\n        (1, '2020-01-05', 30),\n        (1, '2020-01-06', 35),\n        (1, '2020-01-07', 40)]\n\ndf = spark.createDataFrame(data, ['item', 'date', 'sales'])\n\n# Calculate MA(3) using lag function\ndf = df.withColumn('ma_3', (col('sales') + lag('sales', 1).over(Window.partitionBy('item').orderBy('date')) +\n                            lag('sales', 2).over(Window.partitionBy('item').orderBy('date'))) / 3)\n\n# Show the result\ndf.show()\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the code that you want to be generated (Press Q to quit): q"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Assignment 2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
